{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-09T10:17:28.944972600Z",
     "start_time": "2023-08-09T10:17:27.712973600Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('C:/Users/dinle/Code/Learning/Py_Code/AI_Learning/mnist')\n",
    "sys.path.append('C:/Users/dinle/Code/Learning/Py_Code/AI_Learning/NodeLayer')\n",
    "from NodeLayer.Networks.multi_layer_net_extend import MultiLayerNetExtend as MLE1\n",
    "from NodeLayer.Networks.simple_convnet import SimpleConvNet as CVS1\n",
    "from NodeLayer.Networks.deep_convnet import DeepConvNet as CVD1\n",
    "from mnist.common.multi_layer_net_extend import MultiLayerNetExtend as MLE2\n",
    "from mnist.ch07.simple_convnet import SimpleConvNet as CVS2\n",
    "from mnist.ch08.deep_convnet import DeepConvNet as CVD2\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist.dataset.mnist import load_mnist\n",
    "from mnist.common.util import smooth_curve\n",
    "from mnist.common.optimizer import *\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "x_train = x_train[:1000]\n",
    "t_train = t_train[:1000]\n",
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]\n",
    "batch_size = 100\n",
    "max_iterations = 1000\n",
    "print_iter = 100\n",
    "mi = np.arange(max_iterations)\n",
    "optimizer = AdaGrad()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T10:17:29.065655300Z",
     "start_time": "2023-08-09T10:17:28.947003200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test(test_list, max_acc=None):\n",
    "    networks = {}\n",
    "    train_acc = {}\n",
    "    train_loss = {}\n",
    "    test_acc = {}\n",
    "    test_loss = {}\n",
    "    optimizer = {}\n",
    "    total_step = {}\n",
    "    time_record = {}\n",
    "\n",
    "    for key in test_list.keys():\n",
    "        # 기록 리스트 생성\n",
    "        train_acc[key] = []\n",
    "        train_loss[key] = []\n",
    "        test_acc[key] = []\n",
    "        test_loss[key] = []\n",
    "        total_step[key] = 0\n",
    "        time_record[key] = 0\n",
    "\n",
    "        # nSigmoid 경우 파라미터\n",
    "        # key == 'nSigmoid_8' -> act = nSigmoid, threshold = 8\n",
    "        model = test_list[key]['model']\n",
    "        opt = test_list[key]['opt']\n",
    "        lr = test_list[key]['lr']\n",
    "\n",
    "\n",
    "        # 네트워크 모델 생성\n",
    "        if model == 'MLE1':\n",
    "            act = test_list[key]['act']\n",
    "            std = test_list[key]['std']\n",
    "            dr = test_list[key]['dr']\n",
    "            bn = test_list[key]['bn']\n",
    "            bp = test_list[key]['bp']\n",
    "            do = False\n",
    "            if dr is not None:\n",
    "                do = True\n",
    "            networks[key] = MLE1(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
    "                                output_size=10, use_dropout=do, dropout_ration=dr, activation=act, weight_init_std=std, use_batchnorm=bn, batch_pos=bp)\n",
    "        elif model == 'MLE2':\n",
    "            act = test_list[key]['act']\n",
    "            std = test_list[key]['std']\n",
    "            dr = test_list[key]['dr']\n",
    "            bn = test_list[key]['bn']\n",
    "            do = False\n",
    "            if dr is not None:\n",
    "                do = True\n",
    "            networks[key] = MLE2(input_size=784, hidden_size_list=[100, 100, 100, 100],\n",
    "                                 output_size=10, use_dropout=do, dropout_ration=dr, activation=act, weight_init_std=std, use_batchnorm=bn)\n",
    "        elif model == 'CVS1':\n",
    "            networks[key] = CVS1()\n",
    "        elif model == 'CVS2':\n",
    "            networks[key] = CVS2()\n",
    "        elif model == 'CVD1':\n",
    "            networks[key] = CVD1()\n",
    "        elif model == 'CVD2':\n",
    "            networks[key] = CVD2()\n",
    "        else:\n",
    "            assert 'no model' + model\n",
    "\n",
    "        # optimizer 생성\n",
    "        if opt == 'SGD':\n",
    "            optimizer[key] = SGD(lr)\n",
    "        elif opt == 'AdaGrad':\n",
    "            optimizer[key] = AdaGrad(lr)\n",
    "        elif opt == 'Adam':\n",
    "            optimizer[key] = Adam(lr)\n",
    "        else:\n",
    "            assert 'no opt' + opt\n",
    "\n",
    "    # 파라미터 통일\n",
    "    networks1 = networks['My']\n",
    "    networks2 = networks['Text']\n",
    "    for k in networks1.params.keys():\n",
    "        for i in range(networks1.params[k].shape[0]):\n",
    "            networks1.params[k][i] = networks2.params[k][i].copy()\n",
    "\n",
    "    # 학습\n",
    "    for i in range(max_iterations):\n",
    "        # if 0 not in total_step.values():\n",
    "        #     print(\"All test list training Done\\nStep: \" + str(i))\n",
    "        #     break\n",
    "\n",
    "        # mini-batch train\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "\n",
    "        # mini-batch test\n",
    "        batch_mask_t = np.random.choice(test_size, batch_size)\n",
    "        x_batch_t = x_test[batch_mask_t]\n",
    "        t_batch_t = t_test[batch_mask_t]\n",
    "\n",
    "        # print_iter 회마다 경과 출력\n",
    "        if i % print_iter == 0:\n",
    "            print( \"=\"*15 + \"iteration:\" + str(i) + \"=\"*15)\n",
    "            print(\"{:^9}|{:^9}|{:^9}|{:^9}\".format('model','time','acc','loss'))\n",
    "\n",
    "        # 학습 & 추론 & 기록\n",
    "        for key in test_list.keys():\n",
    "            if total_step[key] != 0:\n",
    "                # Max acc 에 도달해 학습이 끝난 test model\n",
    "                continue\n",
    "            else:\n",
    "                start = time.time()\n",
    "                # CV 모델 데이터 처리\n",
    "                if test_list[key]['model'].startswith('CV'):\n",
    "                    x_batch = x_batch.reshape(-1, 1, 28, 28)\n",
    "                    x_batch_t = x_batch_t.reshape(-1, 1, 28, 28)\n",
    "                #\n",
    "                # # 학습(역전파)\n",
    "                # b_strat = time.time()\n",
    "\n",
    "                grads = networks[key].gradient(x_batch, t_batch)\n",
    "                optimizer[key].update(networks[key].params, grads)\n",
    "                # b_end = time.time()\n",
    "                # print(key, \"학습: \", b_end - b_strat)\n",
    "\n",
    "                # 추론(순전파)\n",
    "                if key.endswith(\"1\"):\n",
    "                    # f_strat = time.time()\n",
    "                    tr_acc, tr_loss = networks[key].acc_and_loss(x_batch, t_batch)\n",
    "                    ts_acc, ts_loss = networks[key].acc_and_loss(x_batch_t, t_batch_t)\n",
    "                    f_end = time.time()\n",
    "                    # print(key, \"추론: \", f_end - f_strat)\n",
    "                else:\n",
    "                    # f_strat = time.time()\n",
    "                    if test_list[key]['model'].startswith('CV'):\n",
    "                        tr_acc = networks[key].accuracy(x_batch, t_batch, batch_size)\n",
    "                        ts_acc = networks[key].accuracy(x_batch_t, t_batch_t, batch_size)\n",
    "                    else:\n",
    "                        tr_acc = networks[key].accuracy(x_batch, t_batch)\n",
    "                        ts_acc = networks[key].accuracy(x_batch_t, t_batch_t)\n",
    "                    tr_loss = networks[key].loss(x_batch, t_batch)\n",
    "                    ts_loss = networks[key].loss(x_batch_t, t_batch_t)\n",
    "                    # f_end = time.time()\n",
    "                    # print(key, \"추론: \", f_end - f_strat)\n",
    "\n",
    "                # 기록\n",
    "                train_acc[key].append(tr_acc)\n",
    "                train_loss[key].append(tr_loss)\n",
    "                test_acc[key].append(ts_acc)\n",
    "                test_loss[key].append(ts_loss)\n",
    "                end = time.time()\n",
    "                time_record[key] += (end-start)\n",
    "\n",
    "                # max accuracy 도달 해당 모델 학습 종료\n",
    "                if max_acc and max_acc <= ts_acc:\n",
    "                    total_step[key] = i\n",
    "                    print(key + \" training end!\\nacc : \" + str(ts_acc) + \" step: \" + str(i))\n",
    "\n",
    "                # print_iter 회마다 경과 출력\n",
    "                if i % print_iter == 0:\n",
    "                    print(\"{:^9}| {:0<7.3f} | {:0<.5f} | {:0<.5f}\".format(key, time_record[key],tr_acc,tr_loss))\n",
    "\n",
    "    return train_acc, train_loss, test_acc, test_loss, total_step\n",
    "\n",
    "\n",
    "def plot(label, datas, t_list, *y_lim):\n",
    "    for key in t_list:\n",
    "        plt.plot( smooth_curve(datas[key]), markevery=50, label=key)\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(label)\n",
    "    if y_lim:\n",
    "        plt.ylim(y_lim)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T10:17:29.099164100Z",
     "start_time": "2023-08-09T10:17:29.080163600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============iteration:0===============\n",
      "  model  |  time   |   acc   |  loss   \n",
      "   My    | 0.01500 | 0.16000 | 2.26446\n",
      "  Text   | 0.01300 | 0.16000 | 2.26446\n",
      "===============iteration:100===============\n",
      "  model  |  time   |   acc   |  loss   \n",
      "   My    | 1.43500 | 0.63000 | 1.43158\n",
      "  Text   | 1.13600 | 0.63000 | 1.43158\n",
      "===============iteration:200===============\n",
      "  model  |  time   |   acc   |  loss   \n",
      "   My    | 2.81000 | 0.86000 | 0.73771\n",
      "  Text   | 2.22300 | 0.86000 | 0.73771\n",
      "===============iteration:300===============\n",
      "  model  |  time   |   acc   |  loss   \n",
      "   My    | 4.04000 | 0.92000 | 0.41375\n",
      "  Text   | 3.31100 | 0.92000 | 0.41375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 28>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m test_list \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      2\u001B[0m              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMy\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m      3\u001B[0m                  {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMLE1\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopt\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSGD\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mact\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhe\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdr\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mNone\u001B[39;00m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbn\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mFalse\u001B[39;00m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbp\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m1\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m0.01\u001B[39m},\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m             \u001B[38;5;66;03m#     {'model':'mt2','act':'relu','std':'he','dr':None,'bn':True,'lr':0.01},\u001B[39;00m\n\u001B[0;32m     24\u001B[0m              }\n\u001B[1;32m---> 28\u001B[0m train_acc, train_loss, test_acc, test_loss, total_step \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.99\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36mtest\u001B[1;34m(test_list, max_acc)\u001B[0m\n\u001B[0;32m    108\u001B[0m     x_batch_t \u001B[38;5;241m=\u001B[39m x_batch_t\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m28\u001B[39m, \u001B[38;5;241m28\u001B[39m)\n\u001B[0;32m    109\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    110\u001B[0m \u001B[38;5;66;03m# # 학습(역전파)\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;66;03m# b_strat = time.time()\u001B[39;00m\n\u001B[1;32m--> 113\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[43mnetworks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgradient\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m optimizer[key]\u001B[38;5;241m.\u001B[39mupdate(networks[key]\u001B[38;5;241m.\u001B[39mparams, grads)\n\u001B[0;32m    115\u001B[0m \u001B[38;5;66;03m# b_end = time.time()\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;66;03m# print(key, \"학습: \", b_end - b_strat)\u001B[39;00m\n\u001B[0;32m    117\u001B[0m \n\u001B[0;32m    118\u001B[0m \u001B[38;5;66;03m# 추론(순전파)\u001B[39;00m\n",
      "File \u001B[1;32m~\\Code\\Learning\\Py_Code\\AI_Learning\\Node_Layer_Network\\Networks\\multi_layer_net_extend.py:188\u001B[0m, in \u001B[0;36mMultiLayerNetExtend.gradient\u001B[1;34m(self, x, t)\u001B[0m\n\u001B[0;32m    183\u001B[0m layers\u001B[38;5;241m.\u001B[39mreverse()\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m layers:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;66;03m# print(dout)\u001B[39;00m\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;66;03m# print(layer)\u001B[39;00m\n\u001B[1;32m--> 188\u001B[0m     dout \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# 결과 저장\u001B[39;00m\n\u001B[0;32m    191\u001B[0m grads \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mC:\\Users/dinle/Code/Learning/Py_Code/AI_Learning/Node_Layer_Network\\Layers\\layers.py:50\u001B[0m, in \u001B[0;36mAffine.backward\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, y):\n\u001B[1;32m---> 50\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlast_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdW \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_w\u001B[38;5;241m.\u001B[39mdv\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_b\u001B[38;5;241m.\u001B[39mdv\n",
      "File \u001B[1;32mC:\\Users/dinle/Code/Learning/Py_Code/AI_Learning/Node_Layer_Network\\Nodes\\two_node.py:74\u001B[0m, in \u001B[0;36mAdd.backward\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m     72\u001B[0m db \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# print(\"Add Backward\\n:\", y)\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma_node\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mda\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mb_node\u001B[38;5;241m.\u001B[39mbackward(db)\n",
      "File \u001B[1;32mC:\\Users/dinle/Code/Learning/Py_Code/AI_Learning/Node_Layer_Network\\Nodes\\two_node.py:31\u001B[0m, in \u001B[0;36mDot.backward\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, y):\n\u001B[1;32m---> 31\u001B[0m     da \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbT\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# [128, 10] * [10, 100] -> [128, 100]\u001B[39;00m\n\u001B[0;32m     32\u001B[0m     db \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maT, y)  \u001B[38;5;66;03m# [100, 128] * [128, 10] -> [100, 10]\u001B[39;00m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma_node\u001B[38;5;241m.\u001B[39mbackward(da)\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test_list = {\n",
    "             'My':\n",
    "                 {'model':'MLE1','opt':'SGD','act':'relu','std':'he','dr':None,'bn':False,'bp':1,'lr':0.01},\n",
    "             'Text':\n",
    "                 {'model':'MLE2','opt':'SGD','act':'relu','std':'he','dr':None,'bn':False,'bp':1,'lr':0.01},\n",
    "             # '0.086_My':\n",
    "             #     {'model':'MLE1','opt':'SGD','act':'relu','std':0.086,'dr':None,'bn':False,'bp':1,'lr':0.01},\n",
    "             # '0.086_Text':\n",
    "             #     {'model':'MLE2','opt':'SGD','act':'relu','std':0.086,'dr':None,'bn':False,'bp':1,'lr':0.01},\n",
    "             # 'DpCV1':\n",
    "             #     {'model':'CVD1','opt':'Adam','act':'relu','std':'he','dr':None,'bn':True,'bp':0,'lr':0.01},\n",
    "             # 'DpCV2':\n",
    "             #     {'model':'CVD2','opt':'Adam','act':'relu','std':'he','dr':None,'bn':True,'bp':0,'lr':0.01},\n",
    "             # 'DpCV11':\n",
    "             #     {'model':'CVD1','opt':'Adam','act':'relu','std':'he','dr':None,'bn':True,'bp':0,'lr':0.01},\n",
    "             # 'DpCV22':\n",
    "             #     {'model':'CVD2','opt':'Adam','act':'relu','std':'he','dr':None,'bn':True,'bp':0,'lr':0.01},\n",
    "            # 'Node_BN2':\n",
    "            #      {'model':'mt1','opt':'AdaGrad','act':'relu','std':'he','dr':None,'bn':True,'bp':2,'lr':0.01},\n",
    "            #   'Text':\n",
    "            #     {'model':'mt2','act':'relu','std':'he','dr':None,'bn':False,'lr':0.01},\n",
    "            # 'Text_BN':\n",
    "            #     {'model':'mt2','act':'relu','std':'he','dr':None,'bn':True,'lr':0.01},\n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "train_acc, train_loss, test_acc, test_loss, total_step = test(test_list, 0.99)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-09T10:17:37.671271600Z",
     "start_time": "2023-08-09T10:17:29.099164100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot('train_acc', train_acc, test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T10:17:37.669271600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot('train_loss', train_loss, test_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T10:17:37.669271600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(total_step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T10:17:37.670272100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "\n",
    "plt.plot( smooth_curve(train_acc['My']), markevery=50, label='My')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel('train_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot( smooth_curve(train_acc['Text']), markevery=50, label='Text')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-09T10:17:37.670272100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
